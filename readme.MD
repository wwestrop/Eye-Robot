# What is it?
A program for recognising shapes (be they polygons, printed letters or numbers, handwriting, or any other kind of symbol) in a monochrome image.


# Why?
For me to get a feel for the sort of techniques an artificially intelligent application might make use of (particularly evolutionary algorithms), and indeed to explore if this idea is even viable. 


# How does it work?
The software recognises symbols by analysing a subset of pixels distributed throughout the input image, and seeing whether they are set or unset (i.e. black or white). Black pixels score a certain amount, and white pixels score a certain negative amount. These scores are added together, and the total decides how likely it is that a given image contains a particular symbol. In order to do this, we'll want to check the specific subset of pixels that maximises this score.

Basically the software is trying to provide an answer for the following question: for a given shape, which pixels are "significant"? The hope is that if trained to recognise the letter "A" in both serif and sans-serif fonts, the pixels that make up the serifs would be deemed irrelevant in determining whether the shape was a actually an "A" or not. 

For example, here is a 32Ã—32px image of the letter 'a':

![](/doc/a_small.png)


And here it is magnified: 

![](/doc/a_magnified.png)


We'll pick a number of random pixels to look at (highlighted in orange):

![](/doc/a_random.png)


And if the pixels we look at are inside the shape, yay, we score some points. If they're outside the shape, boo, we lose some points. 


# Training the software 
This is the process that the software uses to decide which subset of pixels are relevant. This happens before it can recognise a symbol. 

Initially, the way I was choosing this subset was by picking a set of pixels at random, as above; and scoring it against the training data (a sample image). This was repeated many many times over, producing many permutations of pixels from within the image. Whichever permutation happened to give the highest score for our training data was the one that was chosen as the model. 

The idea was that this:

![](/doc/a_random.png)


Would converge to this:

![](/doc/a_clustered.png)


# What did I learn?
I had expected that, through sheer brute-forcing randomness, that the training algorithm would eventually converge on a set of pixels that were tightly clustered on the shape being trained (as described above).

This did not happen, although given enough repetitions, it surely would have. The examples below were generated by the software in this way, each using 200,000 rounds, and to me they look like random noise. Perhaps 200,000 tries was just not enough? More investigation needs to be done here. Despite this, these pixel distributions were better than chance at predicting the contents of a different image (though admittedly, these images weren't vastly different-looking than the training data). 

![](/doc/randomised_samples.png)


The concept I took away from that discovery is that, as with biological evolution, it adapts an organism to whatever works, not necessarily whatever might be optimal. 


# Where next?
When training the model, selecting the sampled pixels entirely at random did not work as well as I'd hoped.

During training, because each selected subset is completely random, each one is totally different to the last. If we have a high-scoring set of pixels, rather than trying something entirely different, it makes sense to try something that is only a little bit different to see if we can get closer to a solution. I hypothesised that making these sweeping changes from one generation to the next are not helping us to converge on a solution. From this, I've lifted two more ideas from biological processes to make changes more gradual. The first is that mutations in nature are small (not a total re-write from generation to generation as with our purely random pixel distributions); and the second is mixing up aspects of two pixel-sets, as with breeding in nature, in an attempt to mix-up the best bits of both and produce an overall higher-scoring child (except rather than taking half its genes from each parent, it takes half of the pixels that will be sampled from each parent). The idea is some of the child pixel distributions score higher than the parent they were derived from, and those are the ones we select to take forward. 

However! These features are not implemented yet. Stay tuned! 

Also coming up, things I'd like to look at:
* So far, I'm getting reasonable (but not exceptional) results at recognising the image it was trained on. I'd like to build up a wider library of samples (See /sample-data/ - there are few different 'a' variants, but they are all quite similar). I'd also like to get some handwriting samples being recognised. 
* Performance - In principle, the training algorithm is extremely parallelisable (trivially, I had thought, by calling 'AsParallel()' on the randomly generated list of 'Scorers'). ~~I could convert the input bitmap to a 2-dimensional boolean array. This would save calling `IsPixelSet` repeatedly, avoiding the brightness calculation, which would save approximately 4%, according to Visual Studio's profiler~~ (Done. But I need to benchmark it to be sure, and I was working in a coffee shop with dwindling battery. Didn't want to stress the laptop too much). The training algorithm is also a memory pig. 
* Originally, `TuningParams` was a static bundle of constants. I'd like to at some point randomise these as well and pass varying sets of tuning options to different parts of the program in an attempt to settle on a better training model (you can already see some of this in the code). This is also partly because I chose the constant values by trial-and-error, they may not necessarily be particularly good. 
* I'd like to add the ability to save a trained model to disk and reload it. 
* I'd like to add image normalisation (ie correcting input images for skew, sizing, spacing, etc)
* Further into the future, I'm still pondering how I'd handle training  more than one example image for a given symbol






