# What is it?
A program for recognising shapes (be they polygons, printed letters or numbers, handwriting, or any other kind of symbol) in a monochrome image.


# Why?
For me to get a feel for the sort of techniques an artificially intelligent application might make use of (particularly evolutionary algorithms), and indeed to explore if this idea is even viable. 


# How does it work?
The software recognises symbols by analysing a subset of pixels distributed throughout the input image, and seeing whether they are set or unset (i.e. black or white). Black pixels score a certain amount, and white pixels score a certain negative amount. These scores are added together, and the total decides how likely it is that a given image contains a particular symbol. In order to do this, we'll want to check the specific subset of pixels that maximises this score.

Basically the software is trying to provide an answer for the following question: for a given shape, which pixels are "significant"? The hope is that if trained to recognise the letter "A" in both serif and sans-serif fonts, the pixels that make up the serifs would be deemed irrelevant in determining whether the shape was a actually an "A" or not. 

For example, here is the letter 'a':

And here it is magnified: 

We'll pick a number of random pixels to look at (highlighted in orange):

And if the pixels we look at are inside the shape, yay, score some points. If they're outside the shape, boo, lose some points. 


# Training the software 
This is the process that the software uses to decide which subset of pixels are relevant. This happens before it can recognise a symbol. 

Initially, the way I was choosing this subset was by picking a set of pixels at random, as above; and scoring it against the training data (a sample image). This was repeated many many times over, producing many permutations of pixels from within the image. Whichever permutation happened to give the highest score for our training data was the one that was chosen as the model. 

The idea was that this:

Would converge to this:


# What did I learn?
I had expected that, through sheer brute-forcing randomness, that the training algorithm would eventually converge on a set of pixels that were tightly clustered on the shape being trained (as described).

This did not happen even after hundreds of thousands of permutations, although given enough repetitions, it surely would have. The examples below were generated by the software in this way, and to me they look like random noise. Despite that, these pixel distributions were better than chance at predicting the contents of a different image (though admittedly, these weren't vastly different-looking than the training data). 

The concept I took away from that discovery is that, as with biological evolution, it adapts an organism to whatever works, not necessarily whatever might be optimal. 


# Where next?





